{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzl-thu/PRMLTA/blob/main/cifar10_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pkYfIMiQgm0g"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "rZkONWgngm0h"
      },
      "source": [
        "\n",
        "# Tensors\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays\n",
        "and matrices. In PyTorch, we use tensors to encode the inputs and\n",
        "outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, except that tensors can run on\n",
        "GPUs or other specialized hardware to accelerate computing. If you’re familiar with ndarrays, you’ll\n",
        "be right at home with the Tensor API. If not, follow along in this quick\n",
        "API walkthrough.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Bq36Hqfgm0h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wWIJTkAsgm0h"
      },
      "source": [
        "## Tensor Initialization\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inferred.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ke9VkyTKgm0h"
      },
      "outputs": [],
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "91gvRAiOgm0h"
      },
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w_XutxCmgm0i"
      },
      "outputs": [],
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nfVKHBTjgm0i"
      },
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QzgDKDZBgm0i"
      },
      "outputs": [],
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tGVa2GI7gm0i"
      },
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-NN_Bkz_gm0i"
      },
      "outputs": [],
      "source": [
        "shape = (2, 3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "S1oq-v3bgm0i"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "GiU5qG11gm0i"
      },
      "source": [
        "## Tensor Attributes\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d7x86su0gm0i"
      },
      "outputs": [],
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ML5jRwTNgm0i"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hTJc_VhTgm0i"
      },
      "source": [
        "## Tensor Operations\n",
        "\n",
        "Over 100 tensor operations, including transposing, indexing, slicing,\n",
        "mathematical operations, linear algebra, random sampling, and more are\n",
        "comprehensively described\n",
        "[here](https://pytorch.org/docs/stable/torch.html)_.\n",
        "\n",
        "Each of them can be run on the GPU (at typically higher speeds than on a\n",
        "CPU). If you’re using Colab, allocate a GPU by going to Edit > Notebook\n",
        "Settings.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2vInJIdwgm0i"
      },
      "outputs": [],
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "E1PbRYTmgm0i"
      },
      "source": [
        "Try out some of the operations from the list.\n",
        "If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TJfFOe7qgm0j"
      },
      "source": [
        "**Standard numpy-like indexing and slicing:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0xSuqbTWgm0j"
      },
      "outputs": [],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OZST5H2Cgm0j"
      },
      "source": [
        "**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n",
        "See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)_,\n",
        "another tensor joining op that is subtly different from ``torch.cat``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RsgxY0_5gm0j"
      },
      "outputs": [],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "E2k-NUvygm0j"
      },
      "source": [
        "**Multiplying tensors**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7c__2aSUgm0j"
      },
      "outputs": [],
      "source": [
        "# This computes the element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "D7apA-tWgm0j"
      },
      "source": [
        "This computes the matrix multiplication between two tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6t_lBXtSgm0j"
      },
      "outputs": [],
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fYJHoT7Zgm0j"
      },
      "source": [
        "**In-place operations**\n",
        "Operations that have a ``_`` suffix are in-place. For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5kbr3M2ggm0j"
      },
      "outputs": [],
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "25Z5UsqPgm0j"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss\n",
        "     of history. Hence, their use is discouraged.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pmmdXqRXgm0j"
      },
      "source": [
        "# A toy example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KUxSwl4Sgm0j"
      },
      "source": [
        "In lecture 9, we have presented a simple demo with numpy for classification. Now we show how this can be achieved by pytorch.\n",
        "\n",
        "First, let's prepare our toy dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "X2Ccxuysgm0j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Initialize weights and data\n",
        "N, Din, H, Dout = 128, 64, 64, 1\n",
        "lr = 5e-5\n",
        "\n",
        "# Training data\n",
        "x_train = torch.randn(N, Din)\n",
        "y_train = torch.zeros(N, 1)\n",
        "x_train[:N // 2, 0] = x_train[:N // 2, 0] * 2 + 3\n",
        "y_train[:N // 2, 0] = 1\n",
        "\n",
        "# Test data\n",
        "N_test = N\n",
        "x_test = torch.randn(N_test, Din)\n",
        "y_test = torch.zeros(N_test, 1)\n",
        "x_test[:N_test // 2, 0] = x_test[:N_test // 2, 0] * 2 + 3\n",
        "y_test[:N_test // 2, 0] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BA8Z90jggm0j"
      },
      "source": [
        "Now let's visualize our training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "A7-_u22Kgm0j"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train[:, 0], cmap=plt.cm.Spectral)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "S5zaNNaAgm0j"
      },
      "source": [
        "Now, we define our neural network with one hidden layer (with the dimension being `H`). The neural network is parameterized by two matrices: `theta1` (project input data into hidden space) and `theta2` (project from hidden space to output space):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tjaEFL6jgm0j"
      },
      "outputs": [],
      "source": [
        "theta1 = torch.randn(Din, H, requires_grad=True)\n",
        "theta2 = torch.randn(H, Dout, requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BH7aEAABgm0j"
      },
      "source": [
        "## Forward Propagation and Loss Calculation\n",
        "We can easily use forward propagation to obtain the model's prediction and calculate the cross-entropy loss within few lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5dpA9cojgm0j"
      },
      "outputs": [],
      "source": [
        "h = torch.sigmoid(x_train.matmul(theta1))\n",
        "h.retain_grad()\n",
        "y_pred = torch.sigmoid(h.matmul(theta2))\n",
        "\n",
        "# Calculate loss\n",
        "loss = torch.mean(-(1 - y_train) * torch.log(1 - y_pred) - y_train * torch.log(y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ARJ_bmdSgm0j"
      },
      "source": [
        "## Back Propagation\n",
        "For gradient calculation, pytorch can automatically achieve this by a single call of `loss.backward()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2sqkmhxgm0k",
        "outputId": "365982ae-49f1-4fa8-ad1d-cf530eec394b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dJ / d theta1=\n",
            " tensor([[ 1.1990e-02,  7.6805e-03,  5.9908e-02,  ...,  3.5805e-02,\n",
            "          7.4570e-02, -1.5236e-02],\n",
            "        [-2.4997e-03,  3.9422e-04, -1.2489e-03,  ..., -5.6220e-03,\n",
            "         -1.4718e-02,  4.1617e-03],\n",
            "        [ 2.2548e-04, -2.6993e-03, -8.6221e-04,  ..., -2.3051e-03,\n",
            "         -9.0948e-03,  1.9832e-03],\n",
            "        ...,\n",
            "        [ 2.5351e-03,  1.0206e-03, -9.3648e-04,  ...,  7.3835e-03,\n",
            "          9.5279e-03, -1.3858e-03],\n",
            "        [-6.4446e-05,  1.4141e-04,  7.1078e-03,  ..., -4.2769e-03,\n",
            "         -4.2307e-03,  4.5724e-03],\n",
            "        [-2.9403e-03,  4.6972e-04, -7.2709e-03,  ..., -3.4427e-03,\n",
            "         -6.9470e-03,  2.5657e-03]]) \n",
            "shape of dJ / d theta1: torch.Size([64, 64])\n",
            "dJ / d theta2=\n",
            " tensor([[ 4.4385e-02],\n",
            "        [-5.0683e-02],\n",
            "        [-6.3830e-02],\n",
            "        [ 3.8266e-02],\n",
            "        [ 8.1215e-02],\n",
            "        [-3.4636e-02],\n",
            "        [-1.7895e-02],\n",
            "        [-4.0350e-02],\n",
            "        [-6.6817e-03],\n",
            "        [-3.9522e-02],\n",
            "        [ 1.1135e-02],\n",
            "        [-1.2630e-02],\n",
            "        [ 4.3073e-02],\n",
            "        [-6.9502e-02],\n",
            "        [ 2.7000e-02],\n",
            "        [ 5.5706e-02],\n",
            "        [-9.1116e-02],\n",
            "        [ 6.2177e-02],\n",
            "        [ 4.0351e-02],\n",
            "        [ 7.2007e-02],\n",
            "        [ 1.6760e-02],\n",
            "        [ 1.1683e-02],\n",
            "        [ 2.5804e-02],\n",
            "        [-6.8775e-03],\n",
            "        [ 6.9007e-02],\n",
            "        [-2.8425e-02],\n",
            "        [-3.2626e-02],\n",
            "        [ 3.6276e-03],\n",
            "        [ 3.0347e-02],\n",
            "        [-7.8960e-02],\n",
            "        [-1.7764e-02],\n",
            "        [ 9.3381e-02],\n",
            "        [-7.3097e-02],\n",
            "        [-2.9355e-02],\n",
            "        [ 1.6514e-02],\n",
            "        [ 1.4472e-02],\n",
            "        [-3.2913e-02],\n",
            "        [ 1.2636e-02],\n",
            "        [-4.1934e-03],\n",
            "        [-1.2442e-05],\n",
            "        [ 2.2073e-02],\n",
            "        [ 8.4519e-03],\n",
            "        [ 3.9954e-04],\n",
            "        [ 6.0705e-03],\n",
            "        [ 9.8724e-03],\n",
            "        [-1.6121e-02],\n",
            "        [ 1.5447e-02],\n",
            "        [-9.0080e-03],\n",
            "        [-4.8895e-02],\n",
            "        [-2.6333e-02],\n",
            "        [-1.1331e-01],\n",
            "        [ 5.5005e-03],\n",
            "        [-6.2296e-02],\n",
            "        [ 4.1266e-03],\n",
            "        [ 3.9150e-03],\n",
            "        [-2.7378e-02],\n",
            "        [-1.6476e-02],\n",
            "        [ 1.9762e-02],\n",
            "        [-5.5346e-02],\n",
            "        [ 2.5268e-02],\n",
            "        [ 5.2212e-02],\n",
            "        [-6.7735e-03],\n",
            "        [ 2.7728e-02],\n",
            "        [ 7.9235e-03]]) \n",
            "shape of dJ / d theta2: torch.Size([64, 1])\n"
          ]
        }
      ],
      "source": [
        "loss.backward()\n",
        "\n",
        "# obtain the gradients on theta1 and theta2\n",
        "print('dJ / d theta1=\\n', theta1.grad, \"\\nshape of dJ / d theta1:\", theta1.grad.shape)\n",
        "print('dJ / d theta2=\\n', theta2.grad, \"\\nshape of dJ / d theta2:\", theta2.grad.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fohNiFYvgm0k"
      },
      "source": [
        "We can also inspect the gradient $dJ/dh$, that is the gradient with respect to the activation of the hidden layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3__0MuD7gm0k",
        "outputId": "d5d5aa7e-7fb6-4429-b5ba-8d1df4eb43fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dJ/dh=\n",
            " tensor([[ 1.5533e-04,  1.9420e-04,  8.8764e-04,  ...,  4.0766e-04,\n",
            "          9.7184e-04, -3.1651e-04],\n",
            "        [ 5.6695e-06,  7.0882e-06,  3.2399e-05,  ...,  1.4880e-05,\n",
            "          3.5472e-05, -1.1552e-05],\n",
            "        [ 2.3219e-05,  2.9030e-05,  1.3269e-04,  ...,  6.0939e-05,\n",
            "          1.4528e-04, -4.7313e-05],\n",
            "        ...,\n",
            "        [-2.2218e-03, -2.7777e-03, -1.2696e-02,  ..., -5.8310e-03,\n",
            "         -1.3901e-02,  4.5272e-03],\n",
            "        [-1.7793e-03, -2.2246e-03, -1.0168e-02,  ..., -4.6698e-03,\n",
            "         -1.1133e-02,  3.6257e-03],\n",
            "        [-1.2929e-03, -1.6164e-03, -7.3884e-03,  ..., -3.3932e-03,\n",
            "         -8.0893e-03,  2.6345e-03]])\n",
            "shape of dJ/dh: torch.Size([128, 64])\n"
          ]
        }
      ],
      "source": [
        "print(\"dJ/dh=\\n\", h.grad)\n",
        "print(\"shape of dJ/dh:\", h.grad.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's test if the gradient calculated by pytorch is the same as our analytical solution. We take $\\theta_2$ as an example:"
      ],
      "metadata": {
        "id": "XUyqi_29guTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('dJ / d theta2 (Pytorch)=\\n', theta2.grad)\n",
        "print('dJ / d theta2 (analytical)=\\n', h.T @ (y_pred - y_train) / N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v20u66UDg7Cl",
        "outputId": "bde61206-bcfe-4d4d-d717-146f1b3871ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dJ / d theta2 (Pytorch)=\n",
            " tensor([[ 4.4385e-02],\n",
            "        [-5.0683e-02],\n",
            "        [-6.3830e-02],\n",
            "        [ 3.8266e-02],\n",
            "        [ 8.1215e-02],\n",
            "        [-3.4636e-02],\n",
            "        [-1.7895e-02],\n",
            "        [-4.0350e-02],\n",
            "        [-6.6817e-03],\n",
            "        [-3.9522e-02],\n",
            "        [ 1.1135e-02],\n",
            "        [-1.2630e-02],\n",
            "        [ 4.3073e-02],\n",
            "        [-6.9502e-02],\n",
            "        [ 2.7000e-02],\n",
            "        [ 5.5706e-02],\n",
            "        [-9.1116e-02],\n",
            "        [ 6.2177e-02],\n",
            "        [ 4.0351e-02],\n",
            "        [ 7.2007e-02],\n",
            "        [ 1.6760e-02],\n",
            "        [ 1.1683e-02],\n",
            "        [ 2.5804e-02],\n",
            "        [-6.8775e-03],\n",
            "        [ 6.9007e-02],\n",
            "        [-2.8425e-02],\n",
            "        [-3.2626e-02],\n",
            "        [ 3.6276e-03],\n",
            "        [ 3.0347e-02],\n",
            "        [-7.8960e-02],\n",
            "        [-1.7764e-02],\n",
            "        [ 9.3381e-02],\n",
            "        [-7.3097e-02],\n",
            "        [-2.9355e-02],\n",
            "        [ 1.6514e-02],\n",
            "        [ 1.4472e-02],\n",
            "        [-3.2913e-02],\n",
            "        [ 1.2636e-02],\n",
            "        [-4.1934e-03],\n",
            "        [-1.2442e-05],\n",
            "        [ 2.2073e-02],\n",
            "        [ 8.4519e-03],\n",
            "        [ 3.9954e-04],\n",
            "        [ 6.0705e-03],\n",
            "        [ 9.8724e-03],\n",
            "        [-1.6121e-02],\n",
            "        [ 1.5447e-02],\n",
            "        [-9.0080e-03],\n",
            "        [-4.8895e-02],\n",
            "        [-2.6333e-02],\n",
            "        [-1.1331e-01],\n",
            "        [ 5.5005e-03],\n",
            "        [-6.2296e-02],\n",
            "        [ 4.1266e-03],\n",
            "        [ 3.9150e-03],\n",
            "        [-2.7378e-02],\n",
            "        [-1.6476e-02],\n",
            "        [ 1.9762e-02],\n",
            "        [-5.5346e-02],\n",
            "        [ 2.5268e-02],\n",
            "        [ 5.2212e-02],\n",
            "        [-6.7735e-03],\n",
            "        [ 2.7728e-02],\n",
            "        [ 7.9235e-03]])\n",
            "dJ / d theta2 (analytical)=\n",
            " tensor([[ 4.4385e-02],\n",
            "        [-5.0683e-02],\n",
            "        [-6.3830e-02],\n",
            "        [ 3.8266e-02],\n",
            "        [ 8.1215e-02],\n",
            "        [-3.4636e-02],\n",
            "        [-1.7895e-02],\n",
            "        [-4.0350e-02],\n",
            "        [-6.6817e-03],\n",
            "        [-3.9522e-02],\n",
            "        [ 1.1135e-02],\n",
            "        [-1.2630e-02],\n",
            "        [ 4.3073e-02],\n",
            "        [-6.9502e-02],\n",
            "        [ 2.7000e-02],\n",
            "        [ 5.5706e-02],\n",
            "        [-9.1116e-02],\n",
            "        [ 6.2177e-02],\n",
            "        [ 4.0351e-02],\n",
            "        [ 7.2007e-02],\n",
            "        [ 1.6760e-02],\n",
            "        [ 1.1683e-02],\n",
            "        [ 2.5804e-02],\n",
            "        [-6.8775e-03],\n",
            "        [ 6.9007e-02],\n",
            "        [-2.8425e-02],\n",
            "        [-3.2626e-02],\n",
            "        [ 3.6276e-03],\n",
            "        [ 3.0347e-02],\n",
            "        [-7.8960e-02],\n",
            "        [-1.7764e-02],\n",
            "        [ 9.3381e-02],\n",
            "        [-7.3097e-02],\n",
            "        [-2.9355e-02],\n",
            "        [ 1.6514e-02],\n",
            "        [ 1.4472e-02],\n",
            "        [-3.2913e-02],\n",
            "        [ 1.2636e-02],\n",
            "        [-4.1934e-03],\n",
            "        [-1.2442e-05],\n",
            "        [ 2.2073e-02],\n",
            "        [ 8.4519e-03],\n",
            "        [ 3.9954e-04],\n",
            "        [ 6.0705e-03],\n",
            "        [ 9.8724e-03],\n",
            "        [-1.6121e-02],\n",
            "        [ 1.5447e-02],\n",
            "        [-9.0080e-03],\n",
            "        [-4.8895e-02],\n",
            "        [-2.6333e-02],\n",
            "        [-1.1331e-01],\n",
            "        [ 5.5005e-03],\n",
            "        [-6.2296e-02],\n",
            "        [ 4.1266e-03],\n",
            "        [ 3.9150e-03],\n",
            "        [-2.7378e-02],\n",
            "        [-1.6476e-02],\n",
            "        [ 1.9762e-02],\n",
            "        [-5.5346e-02],\n",
            "        [ 2.5268e-02],\n",
            "        [ 5.2212e-02],\n",
            "        [-6.7735e-03],\n",
            "        [ 2.7728e-02],\n",
            "        [ 7.9235e-03]], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_-Qp2LyUgm0k"
      },
      "source": [
        "## Gradient Descent\n",
        "Next, we can use pytorch's optimizer to perform gradient descent easily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tpuIy3L0gm0k"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD([theta1, theta2], lr=0.01)\n",
        "\n",
        "theta1_orig = theta1.clone().detach()  # record the parameters before gradient descent, we use theta_1 as an example\n",
        "optimizer.step()  # perform gradient descent\n",
        "print('theta_1 before gradient descent:\\n', theta1_orig)\n",
        "print('theta_1 after gradient descent:\\n', theta1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VG8t2Dqugm0k"
      },
      "source": [
        "The parameters have already been updated by `optimizer.step`.\n",
        "We can verify this gradient descent step is equal as our learned formulation:\n",
        "\n",
        "$$\n",
        "\\theta_1\\leftarrow \\theta_1 - \\alpha \\cdot \\frac{\\partial J}{\\partial \\theta_1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nzY47s04gm0k"
      },
      "outputs": [],
      "source": [
        "theta1_new_analytical = theta1_orig - 0.01 * theta1.grad\n",
        "print('theta_1 after gradient descent (analytical):\\n', theta1_new_analytical)\n",
        "print('theta_1 after gradient descent (analytical) - theta_1 after gradient descent (PyTorch):\\n', theta1_new_analytical - theta1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7-sFLCaogm0k"
      },
      "source": [
        "## Training Loop\n",
        "Now, let's perform training on this toy dataset by repeating the above forward & backward & gradient descent pipeline for 10000 times and see how the neural network learns. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EeSLijbPgm0k"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "loss_list = []\n",
        "accuracy_list = []\n",
        "for t in range(10000):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward\n",
        "    h = torch.sigmoid(x_train.matmul(theta1))\n",
        "    y_pred = torch.sigmoid(h.matmul(theta2))\n",
        "    \n",
        "    # Calculate loss\n",
        "    loss = torch.mean(-(1 - y_train) * torch.log(1 - y_pred) - y_train * torch.log(y_pred))\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # Test accuracy\n",
        "    with torch.no_grad():\n",
        "        h_test = torch.sigmoid(x_test.matmul(theta1))\n",
        "        y_pred_test = torch.sigmoid(h_test.matmul(theta2))\n",
        "        accuracy = torch.mean(((y_pred_test > 0.5) == y_test).float()).item() * 100.0\n",
        "        accuracy_list.append(accuracy)\n",
        "    \n",
        "    # Backward\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update weights with gradient descent\n",
        "    optimizer.step()\n",
        "    \n",
        "# Plot\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(\"training steps\")\n",
        "ax1.set_ylabel(\"training loss\")\n",
        "loss_curve = ax1.plot(range(len(loss_list)), loss_list, label=\"training loss\", color=\"tab:blue\")\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel(\"test accuracy (%)\")\n",
        "accuracy_curve = ax2.plot(range(len(accuracy_list)), accuracy_list, label=\"test accuracy\", color=\"tab:orange\")\n",
        "\n",
        "curves = loss_curve + accuracy_curve\n",
        "labels = [c.get_label() for c in curves]\n",
        "ax1.legend(curves, labels, loc=\"center right\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pFQ55fI9gm0k"
      },
      "source": [
        "\n",
        "# Training a Classifier\n",
        "\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "## Training an image classifier\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalize the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "### 1. Load and normalize CIFAR10\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aLbtL1Zwgm0k"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "epsgNZk6gm0k"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7gM5ohaBgm0k"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=4)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1wGAhU82gm0k"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KnqY1e8Xgm0k"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6FPFN7iMgm0l"
      },
      "source": [
        "### 2. Define a Neural Network\n",
        "Here, we define a simple neural network with 2 hidden layers:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_0UUCtcmgm0l"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 768)\n",
        "        self.fc2 = nn.Linear(768, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.flatten(1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net().cuda()  # put the neural network to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SpWdRFV5gm0l"
      },
      "source": [
        "### 3. Define a Loss function and optimizer\n",
        "Let's use a Classification Cross-Entropy loss.\n",
        "For optimizer, we adopt a highly effective one called Adam. \n",
        "\n",
        "Tips: If you are not sure which optimizer to use, try Adam first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "faQUrxhNgm0l"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "k9olMCi8gm0l"
      },
      "source": [
        "### 4. Train the network\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ww2I3_5egm0l"
      },
      "outputs": [],
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].cuda(), data[1].cuda()  # Note that we should also put data and label to GPU to accelerate training\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "RrDurkMvgm0l"
      },
      "source": [
        "Let's quickly save our trained model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IYL6GpGygm0l"
      },
      "outputs": [],
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JYqGTp8Bgm0l"
      },
      "source": [
        "See [here](https://pytorch.org/docs/stable/notes/serialization.html)\n",
        "for more details on saving PyTorch models.\n",
        "\n",
        "### 5. Test the network on the test data\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display images from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Y0S70SJgm0l"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OKBHLhqcgm0l"
      },
      "source": [
        "Next, let's load back in our saved model (note: saving and re-loading the model\n",
        "wasn't necessary here, we only did it to illustrate how to do so):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zxDANMWDgm0l"
      },
      "outputs": [],
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "stQLKI6egm0l"
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wwZjbSlhgm0l"
      },
      "outputs": [],
      "source": [
        "outputs = net(images)\n",
        "print(\"outputs.shape:\", outputs.shape)\n",
        "print(\"outputs:\\n\", outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FMHriZjggm0l"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "The higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UI0q4Cr0gm0l"
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gr1GE-r_gm0l"
      },
      "source": [
        "The results seem ok.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "38cRY_kwgm0l"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0], data[1]\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7YnB_XPugm0l"
      },
      "source": [
        "That looks **way better than chance**, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "That means the network have already learnt something with this small period of training.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4Y20mYXGgm0l"
      },
      "outputs": [],
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Gvh8EXt-gm0l"
      },
      "source": [
        "Okay, so what next?\n",
        "\n",
        "## Exercise: Build a more powerful neural network\n",
        "\n",
        "The previous example is a basic proof of concept of how we can use pytorch to build neural networks. Now it's your turn to build a more powerful neural network!\n",
        "\n",
        "### ResNet\n",
        "ResNet is a deep convolutional neural network, uses residual connections to address vanishing gradients and performance degradation in deep networks.\n",
        "\n",
        "Simply put, the core idea of ResNet is a so called \"skip\" connection:\n",
        "\n",
        "\\begin{align}\\text{without skip}&: y=f(x) \\\\ \\text{with skip}&: y=f(x)+x\\end{align}\n",
        "\n",
        "A ResNet is typically consists of 3 parts: \n",
        "1. The first part uses one convolutional layer to project the input images into a feature space.\n",
        "2. The second part consists of multiple blocks for feature processing.\n",
        "3. The third part performs a spatial pooling and converts the feature into classification results.\n",
        "The building block of the second part is the key of ResNet, which is achieved by BasicBlock class.\n",
        "\n",
        "### Your task: \n",
        "Finish the BasicBlock class and perform training & evaluation using your ResNet. Compare how it performs with the previous vannila neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "htHHt8Aegm0m"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "        self.conv1 = nn.Conv2d(dim, dim, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(dim)\n",
        "        self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += x\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5hjPaIRLgm0m"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, n_blocks, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.blocks = nn.Sequential(*[\n",
        "            BasicBlock(dim=32) for _ in range(n_blocks)\n",
        "        ])\n",
        "        self.linear = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.blocks(out)\n",
        "        out = F.avg_pool2d(out, 32)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "net = ResNet(n_blocks=6).cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xRq47KF0gm0m"
      },
      "source": [
        "Then, it's time to train & test the performance of your neural network! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1cJnwICigm0m"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "net.eval()\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].cuda(), data[1].cuda()\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "B-ciZFXKgm0m"
      },
      "source": [
        "### Your task 2: \n",
        "Load CIFAR100 dataset in torchvision by yourself, then perform train & eval on CIFAR100 dataset.\n",
        "\n",
        "**Note:**The network and optimizer should be re-initialized before training on CIFAR100. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gWgzT23mgm0m"
      },
      "source": [
        "\n",
        "# A Gentle Introduction to ``torch.autograd``\n",
        "\n",
        "``torch.autograd`` is PyTorch’s automatic differentiation engine that powers\n",
        "neural network training. In this section, you will get a basic sense of how ``autograd`` collects gradients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fwpmS_Uhgm0m"
      },
      "source": [
        "In homework 8, you have encountered some matrix calculus equations. For example:\n",
        "\n",
        "\\begin{align}&\\frac{\\partial}{\\partial{X}}\\mathrm{\\text{Tr}}((Y-CX)^T(Y-CX))=-2 C^T (Y-CX)\\end{align}\n",
        "\n",
        "Now, let's see how we can perform this gradient calculation using pytorch's autograd mechanics (**without** the need of knowing the explicit formula of the gradient).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cLZN_fj3gm0m"
      },
      "source": [
        "We first create the matrix ``X``, ``C`` and ``Y``. Note that we pass ``requires_grad=True`` when creating matrix ``X``. This signals to ``autograd`` that every operation on them should be tracked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ISM7cSAUgm0m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "X = torch.randn(4, 4, requires_grad=True)\n",
        "C = torch.randn(4, 4)\n",
        "Y = torch.randn(4, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zTGF81KEgm0m"
      },
      "outputs": [],
      "source": [
        "print('expected gradient on X:\\n', -2 * C.T @ (Y - C @ X))\n",
        "# calculate the result\n",
        "Q=torch.trace((Y-C @ X).T @ (Y-C.matmul(X)))\n",
        "# perform back-propagation\n",
        "Q.backward()\n",
        "print('autograd calculated gradient on X:\\n', X.grad)  # the gradients on X are stored in X.grad "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WssHr9nNgm0m"
      },
      "source": [
        "Nice! The gradient calculated by autograd is the same as our analytical solution!\n",
        "\n",
        "Now, let's re-execute the cell and see what happens!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ow9x1yDXgm0m"
      },
      "outputs": [],
      "source": [
        "print('expected gradient on X:\\n', -2 * C.T @ (Y - C @ X))\n",
        "# calculate the result\n",
        "Q=torch.trace((Y-C @ X).T @ (Y-C.matmul(X)))\n",
        "# perform back-propagation\n",
        "Q.backward()\n",
        "print('autograd calculated gradient on X:\\n', X.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dmKOvEcogm0m"
      },
      "source": [
        "Why in this time the autograd calculated gradient is not the same as our analytical result? This is because every time ``backward()`` function is called, gradients calculated by autograd are **accumulated** into ``X.grad``. \n",
        "\n",
        "As a result, if we are only interested in the gradients for current operations, we must first clear previously stored gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ouE50dBXgm0m"
      },
      "outputs": [],
      "source": [
        "print('expected gradient on X:\\n', -2 * C.T @ (Y - C @ X))\n",
        "Q=torch.trace((Y-C @ X).T @ (Y-C.matmul(X)))\n",
        "X.grad.zero_()  # Important! Clear the previously stored gradients\n",
        "Q.backward()\n",
        "print('autograd calculated gradient on X:\\n', X.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0BMvkW-3gm0m"
      },
      "source": [
        "Works as we expected again!\n",
        "\n",
        "Therefore, when performing neural network training, we will use ``zero_grad`` of optimizer to clear the gradient before performing gradient update."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9U2yUXeRgm0m"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULqtxrmAKE_e",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "02b62211-4a7d-44a9-fb78-7cac06edf275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "theta_1 before gradient descent:\n",
            " tensor([[-0.8476, -0.0746,  1.6060,  ...,  0.0655,  1.2327,  1.5566],\n",
            "        [-1.2382, -1.3372,  0.1522,  ..., -1.5389, -0.5543,  0.4781],\n",
            "        [-0.8741, -0.9685,  0.3821,  ..., -0.1423, -0.3998, -1.1256],\n",
            "        ...,\n",
            "        [-0.9507, -0.6412,  0.6762,  ...,  1.6346,  1.7163,  0.5287],\n",
            "        [ 0.3617,  0.0284,  0.7862,  ..., -0.4626,  0.0907,  0.4144],\n",
            "        [-0.3127,  1.0867,  1.2147,  ...,  0.4430,  1.6820,  1.9812]])\n",
            "theta_1 after gradient descent:\n",
            " tensor([[-0.8480, -0.0741,  1.6059,  ...,  0.0653,  1.2325,  1.5566],\n",
            "        [-1.2382, -1.3373,  0.1523,  ..., -1.5389, -0.5543,  0.4781],\n",
            "        [-0.8742, -0.9684,  0.3821,  ..., -0.1424, -0.3999, -1.1256],\n",
            "        ...,\n",
            "        [-0.9508, -0.6412,  0.6761,  ...,  1.6346,  1.7162,  0.5287],\n",
            "        [ 0.3618,  0.0284,  0.7862,  ..., -0.4626,  0.0907,  0.4144],\n",
            "        [-0.3126,  1.0868,  1.2147,  ...,  0.4430,  1.6821,  1.9812]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD([theta1, theta2], lr=0.01)\n",
        "\n",
        "theta1_orig = theta1.clone().detach()  # record the parameters before gradient descent, we use theta_1 as an example\n",
        "optimizer.step()  # perform gradient descent\n",
        "print('theta_1 before gradient descent:\\n', theta1_orig)\n",
        "print('theta_1 after gradient descent:\\n', theta1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjsSmKN2gm0n"
      },
      "source": [
        "The parameters have already been updated by `optimizer.step`.\n",
        "We can verify this gradient descent step is equal as our learned formulation:\n",
        "\n",
        "$$\n",
        "\\theta_1\\leftarrow \\theta_1 - \\alpha \\cdot \\frac{\\partial J}{\\partial \\theta_1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQtQeVXhgm0n",
        "outputId": "571aab92-87dd-468b-d850-8ef6312b6aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "theta_1 after gradient descent (analytical):\n",
            " tensor([[-0.8480, -0.0741,  1.6059,  ...,  0.0653,  1.2325,  1.5566],\n",
            "        [-1.2382, -1.3373,  0.1523,  ..., -1.5389, -0.5543,  0.4781],\n",
            "        [-0.8742, -0.9684,  0.3821,  ..., -0.1424, -0.3999, -1.1256],\n",
            "        ...,\n",
            "        [-0.9508, -0.6412,  0.6761,  ...,  1.6346,  1.7162,  0.5287],\n",
            "        [ 0.3618,  0.0284,  0.7862,  ..., -0.4626,  0.0907,  0.4144],\n",
            "        [-0.3126,  1.0868,  1.2147,  ...,  0.4430,  1.6821,  1.9812]])\n",
            "theta_1 after gradient descent (analytical) - theta_1 after gradient descent (PyTorch):\n",
            " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ],
      "source": [
        "theta1_new_analytical = theta1_orig - 0.01 * theta1.grad\n",
        "print('theta_1 after gradient descent (analytical):\\n', theta1_new_analytical)\n",
        "print('theta_1 after gradient descent (analytical) - theta_1 after gradient descent (PyTorch):\\n', theta1_new_analytical - theta1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1SqWVsIJ3UX",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Training Loop\n",
        "Now, let's perform training on this toy dataset by repeating the above forward & backward & gradient descent pipeline for 10000 times and see how the neural network learns. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "KtXvfz1byfZb",
        "outputId": "5eccb007-ddfe-4e6e-e9b4-640a2a12e0f2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training\n",
        "loss_list = []\n",
        "accuracy_list = []\n",
        "for t in range(10000):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward\n",
        "    h = torch.sigmoid(x_train.matmul(theta1))\n",
        "    y_pred = torch.sigmoid(h.matmul(theta2))\n",
        "    \n",
        "    # Calculate loss\n",
        "    loss = torch.mean(-(1 - y_train) * torch.log(1 - y_pred) - y_train * torch.log(y_pred))\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # Test accuracy\n",
        "    with torch.no_grad():\n",
        "        h_test = torch.sigmoid(x_test.matmul(theta1))\n",
        "        y_pred_test = torch.sigmoid(h_test.matmul(theta2))\n",
        "        accuracy = torch.mean(((y_pred_test > 0.5) == y_test).float()).item() * 100.0\n",
        "        accuracy_list.append(accuracy)\n",
        "    \n",
        "    # Backward\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update weights with gradient descent\n",
        "    optimizer.step()\n",
        "    \n",
        "# Plot\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(\"training steps\")\n",
        "ax1.set_ylabel(\"training loss\")\n",
        "loss_curve = ax1.plot(range(len(loss_list)), loss_list, label=\"training loss\", color=\"tab:blue\")\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel(\"test accuracy (%)\")\n",
        "accuracy_curve = ax2.plot(range(len(accuracy_list)), accuracy_list, label=\"test accuracy\", color=\"tab:orange\")\n",
        "\n",
        "curves = loss_curve + accuracy_curve\n",
        "labels = [c.get_label() for c in curves]\n",
        "ax1.legend(curves, labels, loc=\"center right\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4f3bSAA1eyC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# Training a Classifier\n",
        "\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "## Training an image classifier\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalize the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "### 1. Load and normalize CIFAR10\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9m_Wj1r1eyD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTSsPfYI1eyE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-4mVR4v1eyE",
        "outputId": "d7c18148-1efb-4444-9571-7b638c98ddb9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:06<00:00, 28383578.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=4)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vPiZ9NW1eyE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "yCwWHc331eyE",
        "outputId": "2c60cba8-84f2-45fb-fbeb-d555bac7f420",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ship  cat   horse truck\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbPnPmIC1eyE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 2. Define a Neural Network\n",
        "Here, we define a simple neural network with 2 hidden layers:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SUlBp_K1eyF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3*32*32, 768)\n",
        "        self.fc2 = nn.Linear(768, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.flatten(1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = Net().cuda()  # put the neural network to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIxm3TlP1eyF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 3. Define a Loss function and optimizer\n",
        "Let's use a Classification Cross-Entropy loss.\n",
        "For optimizer, we adopt a highly effective one called Adam. \n",
        "\n",
        "Tips: If you are not sure which optimizer to use, try Adam first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0lbMvoN1eyF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiyR-gC01eyF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 4. Train the network\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uHRF87O1eyF",
        "outputId": "7678aa34-3d28-4983-9a5c-e337b79b73b4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,    20] loss: 2.037\n",
            "[1,    40] loss: 1.822\n",
            "[1,    60] loss: 1.740\n",
            "[1,    80] loss: 1.777\n",
            "[1,   100] loss: 1.682\n",
            "[1,   120] loss: 1.720\n",
            "[1,   140] loss: 1.618\n",
            "[1,   160] loss: 1.586\n",
            "[1,   180] loss: 1.649\n",
            "[1,   200] loss: 1.660\n",
            "[1,   220] loss: 1.610\n",
            "[1,   240] loss: 1.597\n",
            "[1,   260] loss: 1.525\n",
            "[1,   280] loss: 1.569\n",
            "[1,   300] loss: 1.602\n",
            "[1,   320] loss: 1.543\n",
            "[1,   340] loss: 1.580\n",
            "[1,   360] loss: 1.502\n",
            "[1,   380] loss: 1.554\n",
            "[2,    20] loss: 1.441\n",
            "[2,    40] loss: 1.451\n",
            "[2,    60] loss: 1.473\n",
            "[2,    80] loss: 1.457\n",
            "[2,   100] loss: 1.486\n",
            "[2,   120] loss: 1.500\n",
            "[2,   140] loss: 1.477\n",
            "[2,   160] loss: 1.495\n",
            "[2,   180] loss: 1.435\n",
            "[2,   200] loss: 1.448\n",
            "[2,   220] loss: 1.434\n",
            "[2,   240] loss: 1.459\n",
            "[2,   260] loss: 1.439\n",
            "[2,   280] loss: 1.439\n",
            "[2,   300] loss: 1.432\n",
            "[2,   320] loss: 1.430\n",
            "[2,   340] loss: 1.434\n",
            "[2,   360] loss: 1.442\n",
            "[2,   380] loss: 1.464\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].cuda(), data[1].cuda()  # Note that we should also put data and label to GPU to accelerate training\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 20 == 19:    # print every 20 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
        "            running_loss = 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3koUhJxY1eyF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Let's quickly save our trained model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2OGSqZB1eyF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Almk2xs1eyF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "See [here](https://pytorch.org/docs/stable/notes/serialization.html)\n",
        "for more details on saving PyTorch models.\n",
        "\n",
        "### 5. Test the network on the test data\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display images from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Ybfbkz8n1eyF",
        "outputId": "40c7672d-6b90-4d8f-a4f2-01183ba2f473",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GroundTruth:  cat   ship  ship  plane\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZBKiGVO1eyF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Next, let's load back in our saved model (note: saving and re-loading the model\n",
        "wasn't necessary here, we only did it to illustrate how to do so):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW9NR23s1eyG",
        "outputId": "d50e9046-43a8-44bd-a0d2-7c6d6e854e5e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkgSw_gb1eyG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHfZPPjS1eyG",
        "outputId": "01e6043c-8003-4f52-d633-361652398ca2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outputs.shape: torch.Size([128, 10])\n",
            "outputs:\n",
            " tensor([[ 0.0821,  0.8933,  1.1616,  ..., -4.5891,  1.7375, -2.1642],\n",
            "        [ 2.0355,  4.5919, -1.4821,  ..., -3.9441,  3.5322,  5.3908],\n",
            "        [ 4.2417,  4.0741, -1.5205,  ..., -1.9349,  4.4799,  3.7503],\n",
            "        ...,\n",
            "        [ 0.0176,  1.2519,  0.2961,  ..., -0.1408, -1.7792,  0.1353],\n",
            "        [ 0.9415, -0.0453, -0.1328,  ..., -0.3279,  1.3832,  1.4473],\n",
            "        [-2.0166, -0.8862,  0.6704,  ...,  1.5208, -0.9208,  1.0073]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "outputs = net(images)\n",
        "print(\"outputs.shape:\", outputs.shape)\n",
        "print(\"outputs:\\n\", outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSmu0_aZ1eyG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "The higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M42xejT_1eyG",
        "outputId": "27591300-2c03-4998-f110-5cb293a70e3f",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted:  cat   truck ship  plane\n"
          ]
        }
      ],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFKvbb131eyG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The results seem ok.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-FUZ5TH1eyG",
        "outputId": "5074de8c-684d-4a18-8b6b-a1120723440c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 48 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0], data[1]\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcQNK_Lr1eyG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "That looks **way better than chance**, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "That means the network have already learnt something with this small period of training.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ldkDyz-1eyG",
        "outputId": "e333ddff-2e51-4bf7-c395-2fe26043a7fc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for class: plane is 56.8 %\n",
            "Accuracy for class: car   is 49.0 %\n",
            "Accuracy for class: bird  is 20.8 %\n",
            "Accuracy for class: cat   is 20.6 %\n",
            "Accuracy for class: deer  is 36.5 %\n",
            "Accuracy for class: dog   is 44.5 %\n",
            "Accuracy for class: frog  is 64.2 %\n",
            "Accuracy for class: horse is 66.1 %\n",
            "Accuracy for class: ship  is 59.9 %\n",
            "Accuracy for class: truck is 68.7 %\n"
          ]
        }
      ],
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf-9-yZt1eyG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Okay, so what next?\n",
        "\n",
        "## Exercise: Build a more powerful neural network\n",
        "\n",
        "The previous example is a basic proof of concept of how we can use pytorch to build neural networks. Now it's your turn to build a more powerful neural network!\n",
        "\n",
        "### ResNet\n",
        "ResNet is a deep convolutional neural network, uses residual connections to address vanishing gradients and performance degradation in deep networks.\n",
        "\n",
        "Simply put, the core idea of ResNet is a so called \"skip\" connection:\n",
        "\n",
        "\\begin{align}\\text{without skip}&: y=f(x) \\\\ \\text{with skip}&: y=f(x)+x\\end{align}\n",
        "\n",
        "A ResNet is typically consists of 3 parts: \n",
        "1. The first part uses one convolutional layer to project the input images into a feature space.\n",
        "2. The second part consists of multiple blocks for feature processing.\n",
        "3. The third part performs a spatial pooling and converts the feature into classification results.\n",
        "The building block of the second part is the key of ResNet, which is achieved by BasicBlock class.\n",
        "\n",
        "### Your task: \n",
        "Finish the BasicBlock class and perform training & evaluation using your ResNet. Compare how it performs with the previous vannila neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWgF9jXw1eyG",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "        self.conv1 = nn.Conv2d(dim, dim, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(dim)\n",
        "        self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += x\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw6KYbRbI3iO",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, n_blocks, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.blocks = nn.Sequential(*[\n",
        "            BasicBlock(dim=32) for _ in range(n_blocks)\n",
        "        ])\n",
        "        self.linear = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.blocks(out)\n",
        "        out = F.avg_pool2d(out, 32)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "net = ResNet(n_blocks=6).cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfoa4M5jPp-7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Then, it's time to train & test the performance of your neural network! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NSudsdm1eyG",
        "outputId": "662e0767-5e7a-448c-991f-fa2d67b25f0e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,    20] loss: 2.010\n",
            "[1,    40] loss: 1.757\n",
            "[1,    60] loss: 1.644\n",
            "[1,    80] loss: 1.619\n",
            "[1,   100] loss: 1.545\n",
            "[1,   120] loss: 1.542\n",
            "[1,   140] loss: 1.501\n",
            "[1,   160] loss: 1.476\n",
            "[1,   180] loss: 1.440\n",
            "[1,   200] loss: 1.410\n",
            "[1,   220] loss: 1.361\n",
            "[1,   240] loss: 1.356\n",
            "[1,   260] loss: 1.338\n",
            "[1,   280] loss: 1.332\n",
            "[1,   300] loss: 1.283\n",
            "[1,   320] loss: 1.245\n",
            "[1,   340] loss: 1.267\n",
            "[1,   360] loss: 1.230\n",
            "[1,   380] loss: 1.190\n",
            "[2,    20] loss: 1.153\n",
            "[2,    40] loss: 1.162\n",
            "[2,    60] loss: 1.186\n",
            "[2,    80] loss: 1.138\n",
            "[2,   100] loss: 1.111\n",
            "[2,   120] loss: 1.131\n",
            "[2,   140] loss: 1.126\n",
            "[2,   160] loss: 1.126\n",
            "[2,   180] loss: 1.073\n",
            "[2,   200] loss: 1.071\n",
            "[2,   220] loss: 1.035\n",
            "[2,   240] loss: 1.046\n",
            "[2,   260] loss: 1.049\n",
            "[2,   280] loss: 1.059\n",
            "[2,   300] loss: 1.010\n",
            "[2,   320] loss: 1.018\n",
            "[2,   340] loss: 0.977\n",
            "[2,   360] loss: 1.005\n",
            "[2,   380] loss: 0.957\n",
            "Accuracy of the network on the 10000 test images: 60 %\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 20 == 19:    # print every 20 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "net.eval()\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].cuda(), data[1].cuda()\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O02gaS9NAwu0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Your task 2: \n",
        "Load CIFAR100 dataset in torchvision by yourself, then perform train & eval on CIFAR100 dataset.\n",
        "\n",
        "**Note:**The network and optimizer should be re-initialized before training on CIFAR100. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC6CgPRXG6dF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "# A Gentle Introduction to ``torch.autograd``\n",
        "\n",
        "``torch.autograd`` is PyTorch’s automatic differentiation engine that powers\n",
        "neural network training. In this section, you will get a basic sense of how ``autograd`` collects gradients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAfL8QFyIVix",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In homework 8, you have encountered some matrix calculus equations. For example:\n",
        "\n",
        "\\begin{align}&\\frac{\\partial}{\\partial{X}}\\mathrm{\\text{Tr}}((Y-CX)^T(Y-CX))=-2 C^T (Y-CX)\\end{align}\n",
        "\n",
        "Now, let's see how we can perform this gradient calculation using pytorch's autograd mechanics (**without** the need of knowing the explicit formula of the gradient).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdGbJVerN9R3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We first create the matrix ``X``, ``C`` and ``Y``. Note that we pass ``requires_grad=True`` when creating matrix ``X``. This signals to ``autograd`` that every operation on them should be tracked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bra0cSMVIVix",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "X = torch.randn(4, 4, requires_grad=True)\n",
        "C = torch.randn(4, 4)\n",
        "Y = torch.randn(4, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Ll2LNtIViy",
        "outputId": "4165ffa9-326b-49b1-f767-0c113c8371f2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "expected gradient on X:\n",
            "\n",
            "autograd calculated gradient on X:\n",
            " tensor([[  7.1441,   5.9599, -12.2284,  -4.2436],\n",
            "        [ -0.0804,   7.4010,  -2.1676,  -3.2257],\n",
            "        [ -0.3697,  -0.9004,  -0.1805,  -0.8725],\n",
            "        [ -3.0835,  -1.3337,   2.0578,   5.0140]])\n"
          ]
        }
      ],
      "source": [
        "print('expected gradient on X:\\n', -2 * C.T @ (Y - C @ X))\n",
        "# calculate the result\n",
        "Q=torch.trace((Y-C @ X).T @ (Y-C.matmul(X)))\n",
        "# perform back-propagation\n",
        "Q.backward()\n",
        "print('autograd calculated gradient on X:\\n', X.grad)  # the gradients on X are stored in X.grad "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbC649zaQI3A",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Nice! The gradient calculated by autograd is the same as our analytical solution!\n",
        "\n",
        "Now, let's re-execute the cell and see what happens!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQuHIlsDRJ07",
        "outputId": "15618c9e-5d50-45e0-a52d-348e225c106a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "expected gradient on X:\n",
            " tensor([[  7.1441,   5.9599, -12.2284,  -4.2436],\n",
            "        [ -0.0804,   7.4010,  -2.1676,  -3.2257],\n",
            "        [ -0.3697,  -0.9004,  -0.1805,  -0.8725],\n",
            "        [ -3.0835,  -1.3337,   2.0578,   5.0140]], grad_fn=<MmBackward0>)\n",
            "autograd calculated gradient on X:\n",
            " tensor([[ 14.2882,  11.9197, -24.4569,  -8.4872],\n",
            "        [ -0.1608,  14.8019,  -4.3352,  -6.4514],\n",
            "        [ -0.7395,  -1.8008,  -0.3610,  -1.7449],\n",
            "        [ -6.1670,  -2.6675,   4.1155,  10.0280]])\n"
          ]
        }
      ],
      "source": [
        "print('expected gradient on X:\\n', -2 * C.T @ (Y - C @ X))\n",
        "# calculate the result\n",
        "Q=torch.trace((Y-C @ X).T @ (Y-C.matmul(X)))\n",
        "# perform back-propagation\n",
        "Q.backward()\n",
        "print('autograd calculated gradient on X:\\n', X.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJqUu7WXRNJI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Why in this time the autograd calculated gradient is not the same as our analytical result? This is because every time ``backward()`` function is called, gradients calculated by autograd are **accumulated** into ``X.grad``. \n",
        "\n",
        "As a result, if we are only interested in the gradients for current operations, we must first clear previously stored gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN3YfuBRTGMJ",
        "outputId": "3460c28f-b7fe-46d5-fad7-a5e1c5dce4e7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "expected gradient on X:\n",
            " tensor([[  7.1441,   5.9599, -12.2284,  -4.2436],\n",
            "        [ -0.0804,   7.4010,  -2.1676,  -3.2257],\n",
            "        [ -0.3697,  -0.9004,  -0.1805,  -0.8725],\n",
            "        [ -3.0835,  -1.3337,   2.0578,   5.0140]], grad_fn=<MmBackward0>)\n",
            "autograd calculated gradient on X:\n",
            " tensor([[  7.1441,   5.9599, -12.2284,  -4.2436],\n",
            "        [ -0.0804,   7.4010,  -2.1676,  -3.2257],\n",
            "        [ -0.3697,  -0.9004,  -0.1805,  -0.8725],\n",
            "        [ -3.0835,  -1.3337,   2.0578,   5.0140]])\n"
          ]
        }
      ],
      "source": [
        "print('expected gradient on X:\\n', -2 * C.T @ (Y - C @ X))\n",
        "Q=torch.trace((Y-C @ X).T @ (Y-C.matmul(X)))\n",
        "X.grad.zero_()  # Important! Clear the previously stored gradients\n",
        "Q.backward()\n",
        "print('autograd calculated gradient on X:\\n', X.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdaO3qgJT1HC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Works as we expected again!\n",
        "\n",
        "Therefore, when performing neural network training, we will use ``zero_grad`` of optimizer to clear the gradient before performing gradient update."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbQJsoy9gm0q"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}